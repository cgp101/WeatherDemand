{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(\"hello\")\n",
        "%pip install --upgrade numpy tensorflow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "hello\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (2.1.3)\nCollecting numpy\n  Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\nRequirement already satisfied: tensorflow in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (2.19.0)\nCollecting tensorflow\n  Using cached tensorflow-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (2.3.1)\nRequirement already satisfied: astunparse>=1.6.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google_pasta>=0.1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt_einsum>=2.3.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf>=5.28.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (5.29.5)\nRequirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (2.32.4)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (78.1.1)\nRequirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: typing_extensions>=3.6.6 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (4.14.1)\nRequirement already satisfied: wrapt>=1.11.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (1.73.1)\nCollecting tensorboard~=2.20.0 (from tensorflow)\n  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: keras>=3.10.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: h5py>=3.11.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (3.14.0)\nRequirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorflow) (0.5.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\nRequirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\nRequirement already satisfied: pillow in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\nRequirement already satisfied: optree in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\nUsing cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\nUsing cached tensorflow-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.4 MB)\nUsing cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\nInstalling collected packages: numpy, tensorboard, tensorflow\n\u001b[2K  Attempting uninstall: numpy\n\u001b[2K    Found existing installation: numpy 2.1.3\n\u001b[2K    Uninstalling numpy-2.1.3:\n\u001b[2K      Successfully uninstalled numpy-2.1.3\n\u001b[2K  Attempting uninstall: tensorboard━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [numpy]\n\u001b[2K    Found existing installation: tensorboard 2.19.032m0/3\u001b[0m [numpy]\n\u001b[2K    Uninstalling tensorboard-2.19.0:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [tensorboard]\n\u001b[2K      Successfully uninstalled tensorboard-2.19.0━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [tensorboard]\n\u001b[2K  Attempting uninstall: tensorflowm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [tensorboard]\n\u001b[2K    Found existing installation: tensorflow 2.19.0━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [tensorboard]\n\u001b[2K    Uninstalling tensorflow-2.19.0:[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [tensorflow]\n\u001b[2K      Successfully uninstalled tensorflow-2.19.0\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [tensorflow]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [tensorflow]3\u001b[0m [tensorflow]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nazureml-dataset-runtime 1.60.0 requires numpy!=1.19.3,<1.24; sys_platform == \"linux\", but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-2.2.6 tensorboard-2.20.0 tensorflow-2.20.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1768105165294
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Import"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "storage_sas_url = \"https://weatherdatastore.blob.core.windows.net/gold-layer/demand_forecast_data.csv?sp=r&st=2026-01-11T02:19:35Z&se=2026-01-25T10:34:35Z&spr=https&sv=2024-11-04&sr=b&sig=cZq9orRZ%2Bez%2Br26Lr9xw4NluBtTo%2BLd0s6oZpH2ZmCk%3D\"\n",
        "df = pd.read_csv(storage_sas_url)\n",
        "\n",
        "print(f\"Rows: {len(df)}\")\n",
        "df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Rows: 26520\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 26520 entries, 0 to 26519\nData columns (total 29 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   datetime            26520 non-null  object \n 1   temperature         26520 non-null  float64\n 2   humidity            26520 non-null  float64\n 3   precipitation       26520 non-null  float64\n 4   rain                26520 non-null  float64\n 5   snowfall            26520 non-null  float64\n 6   wind_speed          26520 non-null  float64\n 7   cloud_cover         26520 non-null  float64\n 8   is_day              26520 non-null  float64\n 9   sunrise             26520 non-null  object \n 10  sunset              26520 non-null  object \n 11  hour                26520 non-null  int64  \n 12  day_of_week         26520 non-null  int64  \n 13  month               26520 non-null  int64  \n 14  is_weekend          26520 non-null  int64  \n 15  daylight_duration   26520 non-null  float64\n 16  precipitation_flag  26520 non-null  int64  \n 17  temp_category       26520 non-null  int64  \n 18  bad_weather_combo   26520 non-null  int64  \n 19  is_peak_hour        26520 non-null  int64  \n 20  season              26520 non-null  int64  \n 21  delivery_demand     26520 non-null  int64  \n 22  energy_demand       26520 non-null  int64  \n 23  retail_demand       26520 non-null  int64  \n 24  ecommerce_demand    26520 non-null  int64  \n 25  delivery_anomaly    26520 non-null  int64  \n 26  energy_anomaly      26520 non-null  int64  \n 27  retail_anomaly      26520 non-null  int64  \n 28  ecommerce_anomaly   26520 non-null  int64  \ndtypes: float64(9), int64(17), object(3)\nmemory usage: 5.9+ MB\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1768241757306
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression -- for base line algo, with ridg "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1768241764084
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = ['rain', 'temp_category', 'precipitation_flag', 'is_weekend']\n",
        "exclude = ['datetime', 'sunrise', 'sunset', \n",
        "           'delivery_demand', 'energy_demand', 'retail_demand', 'ecommerce_demand',\n",
        "           'delivery_anomaly', 'energy_anomaly', 'retail_anomaly', 'ecommerce_anomaly'] + drop_cols\n",
        "\n",
        "feature_cols = [c for c in df.columns if c not in exclude]\n",
        "targets = ['delivery_demand', 'energy_demand', 'retail_demand', 'ecommerce_demand']\n",
        "\n",
        "print(f\"Features ({len(feature_cols)}): {feature_cols}\")\n",
        "\n",
        "X = df[feature_cols]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Features (14): ['temperature', 'humidity', 'precipitation', 'snowfall', 'wind_speed', 'cloud_cover', 'is_day', 'hour', 'day_of_week', 'month', 'daylight_duration', 'bad_weather_combo', 'is_peak_hour', 'season']\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1768241766111
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "scaler = StandardScaler()\n",
        "for target in targets:\n",
        "    print(f\"\\n{target}\")\n",
        "    print(\"-\"*40)\n",
        "    y = df[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    grid = GridSearchCV(\n",
        "        Ridge(), \n",
        "        {'alpha': [0.1, 1.0, 10.0, 100.0]}, \n",
        "        cv=3, scoring='r2'\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    y_pred = grid.best_estimator_.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "    print(f\"Best alpha: {grid.best_params_['alpha']}\")\n",
        "    print(f\"R2: {r2:.4f} | MAE: {mae:.2f} | RMSE: {rmse:.2f}\")\n",
        "    \n",
        "    results.append({'Target': target, 'Model': 'Ridge', 'R2': r2, 'MAE': mae, 'RMSE': rmse})\n",
        "\n",
        "ridge_results = pd.DataFrame(results)\n",
        "print(\"\\n\")\n",
        "print(ridge_results)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\ndelivery_demand\n----------------------------------------\nBest alpha: 1.0\nR2: 0.2735 | MAE: 20.16 | RMSE: 34.27\n\nenergy_demand\n----------------------------------------\nBest alpha: 10.0\nR2: 0.3059 | MAE: 74.18 | RMSE: 129.39\n\nretail_demand\n----------------------------------------\nBest alpha: 1.0\nR2: 0.3325 | MAE: 55.90 | RMSE: 76.90\n\necommerce_demand\n----------------------------------------\nBest alpha: 1.0\nR2: 0.2838 | MAE: 25.18 | RMSE: 42.37\n\n\n             Target  Model        R2        MAE        RMSE\n0   delivery_demand  Ridge  0.273488  20.159292   34.269955\n1     energy_demand  Ridge  0.305857  74.180824  129.389292\n2     retail_demand  Ridge  0.332537  55.896524   76.900292\n3  ecommerce_demand  Ridge  0.283811  25.184596   42.373840\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1768105169003
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis --"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1768241788912
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_results = []\n",
        "for target in targets:\n",
        "    print(f\"\\n{target}\")\n",
        "    print(\"-\"*40)\n",
        "    \n",
        "    y = df[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    grid = GridSearchCV(\n",
        "        RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "        {'n_estimators': [50, 100], 'max_depth': [6, 10, None]},\n",
        "        cv=3, scoring='r2', n_jobs=-1\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = grid.best_estimator_.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "    print(f\"Best params: {grid.best_params_}\")\n",
        "    print(f\"R2: {r2:.4f} | MAE: {mae:.2f} | RMSE: {rmse:.2f}\")\n",
        "    \n",
        "    rf_results.append({'Target': target, 'Model': 'RandomForest', 'R2': r2, 'MAE': mae, 'RMSE': rmse})\n",
        "\n",
        "rf_results = pd.DataFrame(rf_results)\n",
        "print(\"\\n\")\n",
        "print(rf_results)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\ndelivery_demand\n----------------------------------------\nBest params: {'max_depth': 6, 'n_estimators': 50}\nR2: 0.3386 | MAE: 17.76 | RMSE: 32.70\n\nenergy_demand\n----------------------------------------\nBest params: {'max_depth': 6, 'n_estimators': 50}\nR2: 0.4325 | MAE: 51.71 | RMSE: 117.00\n\nretail_demand\n----------------------------------------\nBest params: {'max_depth': 6, 'n_estimators': 100}\nR2: 0.7206 | MAE: 25.29 | RMSE: 49.75\n\necommerce_demand\n----------------------------------------\nBest params: {'max_depth': 6, 'n_estimators': 100}\nR2: 0.3644 | MAE: 21.48 | RMSE: 39.92\n\n\n             Target         Model        R2        MAE        RMSE\n0   delivery_demand  RandomForest  0.338612  17.760145   32.697929\n1     energy_demand  RandomForest  0.432457  51.714195  116.996662\n2     retail_demand  RandomForest  0.720612  25.291558   49.752839\n3  ecommerce_demand  RandomForest  0.364368  21.475408   39.919670\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1768105369224
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_results = []\n",
        "for target in targets:\n",
        "    print(f\"\\n{target}\")\n",
        "    print(\"-\"*40)\n",
        "    y = df[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    grid = GridSearchCV(\n",
        "        XGBRegressor(random_state=42, n_jobs=-1),\n",
        "        {'n_estimators': [50, 100], 'max_depth': [4, 6], 'learning_rate': [0.05, 0.1]},\n",
        "        cv=3, scoring='r2', n_jobs=-1\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = grid.best_estimator_.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "    print(f\"Best params: {grid.best_params_}\")\n",
        "    print(f\"R2: {r2:.4f} | MAE: {mae:.2f} | RMSE: {rmse:.2f}\")\n",
        "    \n",
        "    xgb_results.append({'Target': target, 'Model': 'XGBoost', 'R2': r2, 'MAE': mae, 'RMSE': rmse})\n",
        "\n",
        "xgb_results = pd.DataFrame(xgb_results)\n",
        "print(\"\\n\")\n",
        "print(xgb_results)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\ndelivery_demand\n----------------------------------------\nBest params: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 50}\nR2: 0.3431 | MAE: 17.67 | RMSE: 32.59\n\nenergy_demand\n----------------------------------------\nBest params: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\nR2: 0.4459 | MAE: 49.27 | RMSE: 115.60\n\nretail_demand\n----------------------------------------\nBest params: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 50}\nR2: 0.7288 | MAE: 24.38 | RMSE: 49.02\n\necommerce_demand\n----------------------------------------\nBest params: {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100}\nR2: 0.3709 | MAE: 21.17 | RMSE: 39.71\n\n\n             Target    Model        R2        MAE        RMSE\n0   delivery_demand  XGBoost  0.343059  17.666931   32.587817\n1     energy_demand  XGBoost  0.445881  49.265232  115.604686\n2     retail_demand  XGBoost  0.728766  24.380556   49.021447\n3  ecommerce_demand  XGBoost  0.370903  21.165264   39.713944\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1768241809349
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "mlp_results = []\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for target in targets:\n",
        "    print(f\"\\n{target}\")\n",
        "    print(\"-\"*40)\n",
        "    \n",
        "    y = df[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    # Scale for MLP\n",
        "    X_train_sc = scaler.fit_transform(X_train)\n",
        "    X_test_sc = scaler.transform(X_test)\n",
        "    \n",
        "    grid = GridSearchCV(\n",
        "        MLPRegressor(random_state=42, max_iter=500, early_stopping=True),\n",
        "        {'hidden_layer_sizes': [(64,), (128,), (64, 32)], 'alpha': [0.001, 0.01]},\n",
        "        cv=3, scoring='r2', n_jobs=-1\n",
        "    )\n",
        "    grid.fit(X_train_sc, y_train)\n",
        "    \n",
        "    y_pred = grid.best_estimator_.predict(X_test_sc)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "    print(f\"Best params: {grid.best_params_}\")\n",
        "    print(f\"R2: {r2:.4f} | MAE: {mae:.2f} | RMSE: {rmse:.2f}\")\n",
        "    \n",
        "    mlp_results.append({'Target': target, 'Model': 'MLP', 'R2': r2, 'MAE': mae, 'RMSE': rmse})\n",
        "\n",
        "mlp_results = pd.DataFrame(mlp_results)\n",
        "print(\"\\n\")\n",
        "print(mlp_results)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\ndelivery_demand\n----------------------------------------\nBest params: {'alpha': 0.001, 'hidden_layer_sizes': (64, 32)}\nR2: 0.3044 | MAE: 18.98 | RMSE: 33.53\n\nenergy_demand\n----------------------------------------\nBest params: {'alpha': 0.01, 'hidden_layer_sizes': (64,)}\nR2: 0.4105 | MAE: 57.37 | RMSE: 119.23\n\nretail_demand\n----------------------------------------\nBest params: {'alpha': 0.01, 'hidden_layer_sizes': (64, 32)}\nR2: 0.6987 | MAE: 28.54 | RMSE: 51.67\n\necommerce_demand\n----------------------------------------\nBest params: {'alpha': 0.01, 'hidden_layer_sizes': (128,)}\nR2: 0.3266 | MAE: 23.21 | RMSE: 41.09\n\n\n             Target Model        R2        MAE        RMSE\n0   delivery_demand   MLP  0.304411  18.978676   33.532685\n1     energy_demand   MLP  0.410538  57.365488  119.234489\n2     retail_demand   MLP  0.698704  28.538811   51.666697\n3  ecommerce_demand   MLP  0.326626  23.210979   41.087754\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1768105767890
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def create_sequences(X, y, seq_length=24):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(seq_length, len(X)):\n",
        "        Xs.append(X[i-seq_length:i])\n",
        "        ys.append(y[i])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "lstm_results = []\n",
        "seq_length = 24  # 24 hours lookback\n",
        "\n",
        "for target in targets:\n",
        "    print(f\"\\n{target}\")\n",
        "    print(\"-\"*40)\n",
        "    \n",
        "    # Prepare data\n",
        "    feature_scaler = MinMaxScaler()\n",
        "    target_scaler = MinMaxScaler()\n",
        "    \n",
        "    X_scaled = feature_scaler.fit_transform(X)\n",
        "    y_scaled = target_scaler.fit_transform(df[[target]])\n",
        "    \n",
        "    # Create sequences\n",
        "    X_seq, y_seq = create_sequences(X_scaled, y_scaled.flatten(), seq_length)\n",
        "    \n",
        "    # Split (keep temporal order)\n",
        "    split = int(len(X_seq) * 0.8)\n",
        "    X_train, X_test = X_seq[:split], X_seq[split:]\n",
        "    y_train, y_test = y_seq[:split], y_seq[split:]\n",
        "    \n",
        "    # Build LSTM\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=(seq_length, X.shape[1]), return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    \n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    \n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, \n",
        "              validation_split=0.1, callbacks=[early_stop], verbose=0)\n",
        "    \n",
        "    # Predict & inverse transform\n",
        "    y_pred_scaled = model.predict(X_test, verbose=0)\n",
        "    y_pred = target_scaler.inverse_transform(y_pred_scaled).flatten()\n",
        "    y_actual = target_scaler.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
        "    \n",
        "    # Metrics\n",
        "    r2 = r2_score(y_actual, y_pred)\n",
        "    mae = mean_absolute_error(y_actual, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
        "    \n",
        "    print(f\"R2: {r2:.4f} | MAE: {mae:.2f} | RMSE: {rmse:.2f}\")\n",
        "    \n",
        "    lstm_results.append({'Target': target, 'Model': 'LSTM', 'R2': r2, 'MAE': mae, 'RMSE': rmse})\n",
        "\n",
        "lstm_results = pd.DataFrame(lstm_results)\n",
        "print(\"\\n\")\n",
        "print(lstm_results)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2026-01-11 04:29:30.608842: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "R2: 0.3008 | MAE: 23.53 | RMSE: 40.44\n\n\n             Target Model        R2        MAE        RMSE\n0   delivery_demand  LSTM  0.311765  19.069269   32.253491\n1     energy_demand  LSTM  0.332794  58.681561  117.795284\n2     retail_demand  LSTM  0.710151  28.169811   50.787173\n3  ecommerce_demand  LSTM  0.300850  23.525285   40.444831\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1768106491038
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE = RMSE² =  Sum(Actual - Predicted)^2 / Number of Observations\n",
        "# Ridge\n",
        "ridge_results['MSE'] = ridge_results['RMSE'] ** 2\n",
        "\n",
        "# Random Forest\n",
        "rf_results['MSE'] = rf_results['RMSE'] ** 2\n",
        "\n",
        "# XGBoost\n",
        "xgb_results['MSE'] = xgb_results['RMSE'] ** 2\n",
        "\n",
        "# MLP\n",
        "mlp_results['MSE'] = mlp_results['RMSE'] ** 2\n",
        "\n",
        "# LSTM\n",
        "lstm_results['MSE'] = lstm_results['RMSE'] ** 2\n",
        "\n",
        "# View all\n",
        "print(\"Ridge:\\n\", ridge_results[['Target', 'R2', 'MAE', 'RMSE', 'MSE']])\n",
        "print(\"\\nRandom Forest:\\n\", rf_results[['Target', 'R2', 'MAE', 'RMSE', 'MSE']])\n",
        "print(\"\\nXGBoost:\\n\", xgb_results[['Target', 'R2', 'MAE', 'RMSE', 'MSE']])\n",
        "print(\"\\nMLP:\\n\", mlp_results[['Target', 'R2', 'MAE', 'RMSE', 'MSE']])\n",
        "print(\"\\nLSTM:\\n\", lstm_results[['Target', 'R2', 'MAE', 'RMSE', 'MSE']])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ridge:\n              Target        R2        MAE        RMSE           MSE\n0   delivery_demand  0.273488  20.159292   34.269955   1174.429827\n1     energy_demand  0.305857  74.180824  129.389292  16741.588972\n2     retail_demand  0.332537  55.896524   76.900292   5913.654975\n3  ecommerce_demand  0.283811  25.184596   42.373840   1795.542320\n\nRandom Forest:\n              Target        R2        MAE        RMSE           MSE\n0   delivery_demand  0.338612  17.760145   32.697929   1069.154548\n1     energy_demand  0.432457  51.714195  116.996662  13688.218917\n2     retail_demand  0.720612  25.291558   49.752839   2475.345005\n3  ecommerce_demand  0.364368  21.475408   39.919670   1593.580066\n\nXGBoost:\n              Target        R2        MAE        RMSE           MSE\n0   delivery_demand  0.343059  17.666931   32.587817   1061.965820\n1     energy_demand  0.445881  49.265232  115.604686  13364.443359\n2     retail_demand  0.728766  24.380556   49.021447   2403.102295\n3  ecommerce_demand  0.370903  21.165264   39.713944   1577.197388\n\nMLP:\n              Target        R2        MAE        RMSE           MSE\n0   delivery_demand  0.304411  18.978676   33.532685   1124.440992\n1     energy_demand  0.410538  57.365488  119.234489  14216.863334\n2     retail_demand  0.698704  28.538811   51.666697   2669.447600\n3  ecommerce_demand  0.326626  23.210979   41.087754   1688.203528\n\nLSTM:\n              Target        R2        MAE        RMSE           MSE\n0   delivery_demand  0.311765  19.069269   32.253491   1040.287692\n1     energy_demand  0.332794  58.681561  117.795284  13875.728913\n2     retail_demand  0.710151  28.169811   50.787173   2579.336982\n3  ecommerce_demand  0.300850  23.525285   40.444831   1635.784390\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1768106491688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#saving xgboost \n",
        "import joblib\n",
        "import os\n",
        "\n",
        "os.makedirs('outputs/models', exist_ok=True)\n",
        "\n",
        "for target in targets:\n",
        "    y = df[target]\n",
        "    model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
        "    model.fit(X, y)\n",
        "    \n",
        "    fname = target.replace('_demand', '')\n",
        "    joblib.dump(model, f'outputs/models/{fname}_xgb.pkl')\n",
        "    print(f\"✓ {fname}_xgb.pkl\")\n",
        "\n",
        "print(\"XGBoost model saved for each demand\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✓ delivery_xgb.pkl\n✓ energy_xgb.pkl\n✓ retail_xgb.pkl\n✓ ecommerce_xgb.pkl\nXGBoost model saved for each demand\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1768241810397
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls outputs/models/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "delivery_xgb.pkl  ecommerce_xgb.pkl  energy_xgb.pkl  retail_xgb.pkl\r\n"
        }
      ],
      "execution_count": 8,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.10 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}